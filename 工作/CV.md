1. iou计算公式

2. 损失函数原理

3. 空洞卷积优缺点

4. ohem 和 focal loss 相同和不同

5. ssd对小样本不好的原因

6. DCN原理与实现

7. 感受野含义

8. YOLOv2，v3，v4，v5

9. rcnn一条龙,rpn是什么

10. roi pooling 和roi align区别,代码

11. fpn实现细节

12. anchor在不同层分配方式

13. NMS手写，nms几种方法的比较

14. 交叉熵损失和MSE损失区别

15. BN层gama labada，多卡bn，其他归一化， 有没有可以学习的参数

16. mobile v1，v2

17. 过拟合解决方法

    预训练模型

18. 梯度消失问题

19. 正负样本不均衡问题

20. adam优化器，对比sgd

21. relu的缺点

22. kmeans计算过程

23. 知道哪些滤波器，边缘提取算子，SIFT算子

24. L1L2正则了解吗

25. yolov5怎么检测旋转区域， 

26. python的小知识：xrange和range的区别，dictionary中key和value的限制

27. 感受野

28. focal loss了解吗，.解决难样本问题的方法，ohem与focal loss的相同点和不同点

29. anchor free[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)进展

30. 手写iou loss

31. DCN的原理与实现，感受野的含义

32. fpn的实现细节，anhcor在不同层分配方式

33. 初始学习率如何设定 用到预训练模型的话怎么处理学习率（网格搜索[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)）

34. aspp池化在网络中的作用及池化层有哪些输入参数

35. softmax有什么问题，如何优化

36. ROI pooling 作用

37. 反卷积 转置卷积 了解吗

38. FC作用 和没有FC相比的区别

39. CNN可以不要池化层吗

40. 表达式 cross entropy求导

41. deformable convolution和其他卷积的对比

42. 分割的评价指标 分割中iou怎么算(写代码)

43. Transformer 为什么 能够性能比CNN 好

44. 了解Relu6是啥么

45. svm介绍一下

46. Attention机制 SEnet

47. Unet上采样采用什么方法

48. VC维

49. 对小目标检测识别怎么提升精度

50. 优化[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)：BGD、SGD、小批量梯度下降、动量优化[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)、自适应学习率优化[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)；batch-size如何设置，过大过小会怎样，若硬件满足要求，为什么不能无限增大batch-size

51. 正则化： L1 、L2以及数学角度解释为啥可以减少过拟合；什么样的特征适合L1 or L2 正则化

52. 梯度消失和梯度爆炸的原因和解决方法

53. 过拟合是什么？遇到过拟合该怎么办？

54. L1正则和L2正则的区别是什么？为什么能解决过拟合问题？(回答过拟合的时候提到了L1和L2正则)

55. 数据不平衡怎么办？解决了数据不平衡之后可用数据量太少了怎么办？

56. 通常有什么数据增强的方法？

57. 滤波器，边缘提取算子，SIFT算子，传统图像处理 各种算子

58. 解释空洞卷积

59. 解释上采样和transposed convo和upsample的区别

60. 常见激活函数：sigmoid，softmax，relu；relu不可导的问题咋处理（之前没注意过，应该是采用次梯解决）

61. 介绍下anchor free

62. gcn

63. RoI Pooling 和 RoI Align， 怎么做插值，线性插值，spline插值，写插值公式。这个问题二面和三面都被问到了

64. detection 的发展，从 RCNN 到 CenterNet

65. 在同时考虑 pooling， stride， padding 的情况下，计算 depthwise conv 和 pointwise conv 过程中每一步的计算量和feature map的尺寸

66. 深度学习中评价指标的解释，mAP、PR曲线、AUC

67. 空洞卷积优缺点

68. ssd对小目标不好的原因

69. 介绍cnn 为什么要用池化层？

70. 分类网络最后的fc层的输入为什么可以当做图像的feature？最后的fc层的weights为什么可以当做类的中心？想当类的中心需要做什么预处理？

71. 检测网络中RPN的优点和缺点？

72. SENET

73. Transformer 为什么 能够性能比CNN 好